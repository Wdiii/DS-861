{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS 862 Machine Learning for Business Analysts Fall 2020\n",
    "\n",
    "### Artificial Neural Network\n",
    "\n",
    "#### Submitted by:\n",
    "* Di Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, you will be trying out different structures of MLP and compare the performance. We will again  work on a regression data set and a classification data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# To get reproducible results\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the California housing dataset for our regression exercise. [Here](https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset) is some details about the dataset.\n",
    "#### Attribution Information: \n",
    "- MedInc median income in block\n",
    "- HouseAge median house age in block\n",
    "- AveRooms average number of rooms\n",
    "- AveBedrms average number of bedrooms\n",
    "- Population block population\n",
    "- AveOccup average house occupancy\n",
    "- Latitude house block latitude\n",
    "- Longitude house block longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # We have 8 features and 20640 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1         2         3       4         5      6       7\n",
       "0  8.3252  41.0  6.984127  1.023810   322.0  2.555556  37.88 -122.23\n",
       "1  8.3014  21.0  6.238137  0.971880  2401.0  2.109842  37.86 -122.22\n",
       "2  7.2574  52.0  8.288136  1.073446   496.0  2.802260  37.85 -122.24\n",
       "3  5.6431  52.0  5.817352  1.073059   558.0  2.547945  37.85 -122.25\n",
       "4  3.8462  52.0  6.281853  1.081081   565.0  2.181467  37.85 -122.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "Split the data into training, validation, and testing sets. Scale the training set and apply the same scale onto the validation and testing sets. Make sure you set random seed to the result is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, \n",
    "                                                        test_size = 0.2, random_state = 123)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, \n",
    "                                                      test_size = 0.25, random_state = 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # Instantiate\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_valid_s = scaler.transform(X_valid)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "Now we will fit a neural network. Let's start with a shallow network but with more neurons. Let's try 2 hidden layers, with 15 and 10 neurons repsectively. Use the standard inputs for all other hyperparameters (or something you like). Fit the model and calculate the MSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your neural network here. Use as many boxes as you need.\n",
    "# Instantiate the model structure\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "set_seed(123)\n",
    "Model1 = Sequential([\n",
    "    Dense(15, input_dim = X_train_s.shape[1], activation=\"relu\"), #input dimention 8\n",
    "    Dense(10, activation=\"relu\"),\n",
    "    Dense(1, activation=\"relu\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                135       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 306\n",
      "Trainable params: 306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model1.summary() # 15*(8+1), 10*(15+1), 1*(10+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "Model1.compile(loss = \"mean_squared_error\", optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 1.5962 - val_loss: 0.7276\n",
      "Epoch 2/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.6117 - val_loss: 0.4856\n",
      "Epoch 3/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4839 - val_loss: 0.4392\n",
      "Epoch 4/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4436 - val_loss: 0.4207\n",
      "Epoch 5/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4202 - val_loss: 0.4021\n",
      "Epoch 6/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.4033 - val_loss: 0.3889\n",
      "Epoch 7/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3901 - val_loss: 0.3817\n",
      "Epoch 8/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.3713\n",
      "Epoch 9/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3728 - val_loss: 0.3666\n",
      "Epoch 10/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3671 - val_loss: 0.3610\n",
      "Epoch 11/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3624 - val_loss: 0.3578\n",
      "Epoch 12/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3596 - val_loss: 0.3613\n",
      "Epoch 13/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3542 - val_loss: 0.3494\n",
      "Epoch 14/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3505 - val_loss: 0.3445\n",
      "Epoch 15/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3461 - val_loss: 0.3451\n",
      "Epoch 16/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3437 - val_loss: 0.3392\n",
      "Epoch 17/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3407 - val_loss: 0.3371\n",
      "Epoch 18/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3376 - val_loss: 0.3371\n",
      "Epoch 19/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3352 - val_loss: 0.3351\n",
      "Epoch 20/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3327 - val_loss: 0.3302\n",
      "Epoch 21/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3302 - val_loss: 0.3322\n",
      "Epoch 22/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3281 - val_loss: 0.3237\n",
      "Epoch 23/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3260 - val_loss: 0.3227\n",
      "Epoch 24/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3240 - val_loss: 0.3270\n",
      "Epoch 25/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.3242 - val_loss: 0.3215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19357756408>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "Model1.fit(X_train_s, y_train, epochs=25, validation_data = (X_valid_s, y_valid),\n",
    "         batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0774338],\n",
       "       [0.8028945],\n",
       "       [1.1777669],\n",
       "       ...,\n",
       "       [0.7444577],\n",
       "       [1.8713886],\n",
       "       [3.3993115]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "Model1.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 1ms/step - loss: 0.3132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.313221275806427"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "Model1.evaluate(X_test_s, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "Now we will try a different structure. Instead of a shallow network, let's use a deeper network, but with fewer number of neurons in each later. Let's use 5 hidden layers, but each with [7,5,3,2,2] neurons. Use the standard inputs for all other hyperparameters (or something you like, but be consistent with those in Task 2). Fit the model and calculate the MSE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your neural network here. Use as many boxes as you need.\n",
    "\n",
    "Model2 = Sequential([\n",
    "    Dense(7, input_dim = X_train_s.shape[1], activation=\"relu\"), \n",
    "    Dense(5, activation=\"relu\"),\n",
    "    Dense(3, activation=\"relu\"),\n",
    "    Dense(2, activation=\"relu\"),\n",
    "    Dense(2, activation=\"relu\"),\n",
    "    Dense(1, activation=\"relu\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "Model2.compile(loss = \"mean_squared_error\", optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 2.2760 - val_loss: 0.8465\n",
      "Epoch 2/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.7683 - val_loss: 0.6323\n",
      "Epoch 3/25\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6002 - val_loss: 0.5130\n",
      "Epoch 4/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.5122 - val_loss: 0.4609\n",
      "Epoch 5/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.4652 - val_loss: 0.4294\n",
      "Epoch 6/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.4367 - val_loss: 0.4127\n",
      "Epoch 7/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.4145 - val_loss: 0.3951\n",
      "Epoch 8/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3980 - val_loss: 0.3799\n",
      "Epoch 9/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3875 - val_loss: 0.3733\n",
      "Epoch 10/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3790 - val_loss: 0.3660\n",
      "Epoch 11/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3616\n",
      "Epoch 12/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.3569\n",
      "Epoch 13/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3645 - val_loss: 0.3515\n",
      "Epoch 14/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3504\n",
      "Epoch 15/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.3497\n",
      "Epoch 16/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 0.3463\n",
      "Epoch 17/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3549 - val_loss: 0.3437\n",
      "Epoch 18/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.3439\n",
      "Epoch 19/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.3429\n",
      "Epoch 20/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3397\n",
      "Epoch 21/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3422\n",
      "Epoch 22/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3393\n",
      "Epoch 23/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3376\n",
      "Epoch 24/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.3461\n",
      "Epoch 25/25\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.3448 - val_loss: 0.3402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x193589c79c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "Model2.fit(X_train_s, y_train, epochs=25, validation_data = (X_valid_s, y_valid),\n",
    "         batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 1ms/step - loss: 0.3369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3369347155094147"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "Model2.evaluate(X_test_s, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What do you observe?</b>\n",
    "- Looks like it will take a similar time to run Model1 (2 hidden layers) and Model2 (5 hidden layers).\n",
    "- The second model does not improve the Mean Squared Error for our dataset. So more layers does not always mean high accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "Now let's try to tune our model. Here are the parameters I want you to tune: the optimizer (SGD vs Adam), number of layers, number of neurons, and the activation functions of the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will create a wrapper function\n",
    "def build_model(n_hidden = 1, n_neurons = 5, activation=\"relu\", optimizer = 'Adam', input_dim = 8):\n",
    "    model = Sequential() # Instantiate the model\n",
    "    options = {\"input_dim\": input_dim} # Set options \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(n_neurons, activation = activation, **options)) # Here we are using the input options from before\n",
    "        options = {} # Now we erase the input options so it won't be included in future layers\n",
    "    model.add(Dense(1, activation = activation))\n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your grid search here. Use as many boxes as you need.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "set_seed(123)\n",
    "keras_model = tf.keras.wrappers.scikit_learn.KerasRegressor(build_model) \n",
    "\n",
    "param = {\n",
    "    'n_hidden': [1,2,3,4],\n",
    "    'n_neurons':[5,10,15,20],\n",
    "    'activation':['relu','selu'],\n",
    "    'optimizer': ['Adam', 'SGD']\n",
    "        }\n",
    "\n",
    "Model3 = GridSearchCV(keras_model, param, cv = 2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 1.7404 - val_loss: 0.7673\n",
      "Epoch 2/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.7399 - val_loss: 0.4714\n",
      "Epoch 3/25\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.516 - 0s 1ms/step - loss: 0.5028 - val_loss: 0.4189\n",
      "Epoch 4/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.4093\n",
      "Epoch 5/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.4006 - val_loss: 0.3941\n",
      "Epoch 6/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3846\n",
      "Epoch 7/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3829 - val_loss: 0.3843\n",
      "Epoch 8/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3730\n",
      "Epoch 9/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3674\n",
      "Epoch 10/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.3592\n",
      "Epoch 11/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3591\n",
      "Epoch 12/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.4781\n",
      "Epoch 13/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.3577\n",
      "Epoch 14/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3469\n",
      "Epoch 15/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3430\n",
      "Epoch 16/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3421\n",
      "Epoch 17/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3343\n",
      "Epoch 18/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3365 - val_loss: 0.3407\n",
      "Epoch 19/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3433\n",
      "Epoch 20/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3314\n",
      "Epoch 21/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3332\n",
      "Epoch 22/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3291\n",
      "Epoch 23/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3247 - val_loss: 0.3278\n",
      "Epoch 24/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3350\n",
      "Epoch 25/25\n",
      "387/387 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.3238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000019358B44908>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation': ['relu', 'selu'],\n",
       "                         'n_hidden': [1, 2, 3, 4], 'n_neurons': [5, 10, 15, 20],\n",
       "                         'optimizer': ['Adam', 'SGD']})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model3.fit(X_train_s, y_train, epochs = 25,\n",
    "          validation_data = (X_valid_s, y_valid),\n",
    "          callbacks = tf.keras.callbacks.EarlyStopping(patience=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is your best combination? </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'n_hidden': 2, 'n_neurons': 20, 'optimizer': 'Adam'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What about the evaluation on the test set? </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3106520283419537"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(Model3.predict(X_test_s), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "Now compare with one of your favorite regression model, and tell me what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5180228655178674"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your favorite regression model. Use as many boxes as you need.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_valid_s = scaler.fit_transform(X_train_valid)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "Model4 = LinearRegression()\n",
    "Model4.fit(X_train_valid_s, y_train_valid)\n",
    "mean_squared_error(Model4.predict(X_test_s), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:</b>\n",
    "- Looks like Neural Networks performs much better than the traditional linear regression model. \n",
    "- The MSE is quite small (less than 1), it may bacause our housing target (y) is small, the difference between predicting target and true target won't be large as well. \n",
    "- When I tune my model, it does not stop early since there is improvement on the MSE in Epoch 25. With the best combination, I get my smallest MSE (0.311) among the 4 models. I think I can still improve my model later if I don't use a fixed parameter value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture code, we did a multiclass classification. for this assignment, we will do something simpler. We will only do a binary classification. For this task, we will use the dataset [here](https://www.kaggle.com/iabhishekofficial/mobile-price-classification?select=train.csv). The original output has levels 0,1,2,3. I have merged the 0,1 levels to level 0, and others to level 1. The task is to predict the price level of a cell phone (low = 0 vs high = 1) given a set of mobile feature.\n",
    "\n",
    "#### Attribution Information: \n",
    "- Total energy a battery can store in one time measured in mAh\n",
    "- Has bluetooth or not\n",
    "- Speed at which microprocessor executes instructions\n",
    "- Has dual sim support or not\n",
    "- Front Camera mega pixels\n",
    "- Has 4G or not\n",
    "- Internal Memory in Gigabytes\n",
    "- Mobile Depth in cm\n",
    "- Weight of mobile phone\n",
    "- Number of cores of processor\n",
    "- Primary Camera mega pixels\n",
    "- Pixel Resolution Height\n",
    "- Pixel Resolution Width\n",
    "- Random Access Memory in Mega Bytes\n",
    "- Screen Height of mobile in cm\n",
    "- Screen Width of mobile in cm\n",
    "- longest time that a single battery charge will last when you are\n",
    "- Has 3G or not\n",
    "- Has touch screen or not\n",
    "- Has wifi or not\n",
    "#### Target: # price_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = pd.read_csv('mobile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = mobile.price_range\n",
    "del mobile['price_range']\n",
    "X2 = mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2   2         20       756  2549     9     7         19   \n",
       "1        136        3   6        905      1988  2631    17     3          7   \n",
       "2        145        5   6       1263      1716  2603    11     2          9   \n",
       "3        131        6   9       1216      1786  2769    16     8         11   \n",
       "4        141        2  14       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  \n",
       "0        0             0     1  \n",
       "1        1             1     0  \n",
       "2        1             1     0  \n",
       "3        1             0     0  \n",
       "4        1             1     0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "Split the data into train, validation, and test set. Scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_valid2, X_test2, y_train_valid2, y_test2 = train_test_split(X2, y2, \n",
    "                                                        test_size = 0.2, random_state = 123)\n",
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_train_valid2, y_train_valid2, \n",
    "                                                      test_size = 0.25, random_state = 123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler() # Instantiate\n",
    "X_train2_s = scaler.fit_transform(X_train2)\n",
    "X_valid2_s = scaler.transform(X_valid2)\n",
    "X_test2_s = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have given you enough work for the regression task. We will take it easy with the classification. All you have to do is build a neural network with 3 hidden layers. Becareful of the activation function you use. Return the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels into dummy variables\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train2 = to_categorical(y_train2) # Convert the training output\n",
    "Y_valid2 = to_categorical(y_valid2) # Convert the validation output\n",
    "Y_test2 = to_categorical(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your neural network. Use as many boxes as you need.\n",
    "set_seed(123)\n",
    "Model5 = Sequential([\n",
    "    Dense(15, input_dim = X_train2_s.shape[1], activation=\"relu\"),\n",
    "    Dense(10, activation=\"relu\"),\n",
    "    Dense(5, activation=\"relu\"),\n",
    "    Dense(2, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "Model5.compile(optimizer=tf.keras.optimizers.SGD(lr=0.1),\n",
    "              loss = 'binary_crossentropy', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5933 - val_loss: 0.6874 - val_accuracy: 0.6100\n",
      "Epoch 2/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6583 - val_loss: 0.6719 - val_accuracy: 0.6700\n",
      "Epoch 3/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7150 - val_loss: 0.6330 - val_accuracy: 0.7050\n",
      "Epoch 4/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7650 - val_loss: 0.5406 - val_accuracy: 0.8225\n",
      "Epoch 5/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8667 - val_loss: 0.4213 - val_accuracy: 0.9025\n",
      "Epoch 6/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.9183 - val_loss: 0.3282 - val_accuracy: 0.9375\n",
      "Epoch 7/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.9475 - val_loss: 0.2749 - val_accuracy: 0.9400\n",
      "Epoch 8/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9617 - val_loss: 0.2257 - val_accuracy: 0.9650\n",
      "Epoch 9/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9767 - val_loss: 0.1965 - val_accuracy: 0.9625\n",
      "Epoch 10/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9800 - val_loss: 0.1738 - val_accuracy: 0.9675\n",
      "Epoch 11/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9792 - val_loss: 0.1547 - val_accuracy: 0.9750\n",
      "Epoch 12/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9850 - val_loss: 0.1433 - val_accuracy: 0.9725\n",
      "Epoch 13/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9908 - val_loss: 0.1305 - val_accuracy: 0.9775\n",
      "Epoch 14/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9900 - val_loss: 0.1231 - val_accuracy: 0.9750\n",
      "Epoch 15/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9875 - val_loss: 0.1142 - val_accuracy: 0.9775\n",
      "Epoch 16/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9892 - val_loss: 0.1148 - val_accuracy: 0.9675\n",
      "Epoch 17/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9892 - val_loss: 0.1022 - val_accuracy: 0.9725\n",
      "Epoch 18/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9975 - val_loss: 0.0989 - val_accuracy: 0.9750\n",
      "Epoch 19/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9967 - val_loss: 0.1004 - val_accuracy: 0.9775\n",
      "Epoch 20/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9942 - val_loss: 0.0968 - val_accuracy: 0.9750\n",
      "Epoch 21/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9967 - val_loss: 0.1011 - val_accuracy: 0.9725\n",
      "Epoch 22/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9983 - val_loss: 0.0963 - val_accuracy: 0.9775\n",
      "Epoch 23/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9950 - val_loss: 0.0910 - val_accuracy: 0.9775\n",
      "Epoch 24/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9967 - val_loss: 0.0866 - val_accuracy: 0.9775\n",
      "Epoch 25/25\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9975 - val_loss: 0.0825 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x193589be9c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "Model5.fit(X_train2_s, Y_train2, epochs=25, validation_data = (X_valid2_s, Y_valid2),\n",
    "         batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 921us/step - loss: 0.0753 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07529295235872269, 0.9800000190734863]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy on test set\n",
    "Model5.evaluate(X_test2_s, Y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, compare it with your favoriate classification model, and tell me what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5325"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your favorite classification model. Use as many boxes as you need.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_valid2_s = scaler.fit_transform(X_train_valid2)\n",
    "X_test2_s = scaler.transform(X_test2)\n",
    "Model6 = LogisticRegression()\n",
    "Model6.fit(X_train_valid2_s, y_train_valid2)\n",
    "Model6.score(X_test2, y_test2) # mean accuracy on the given test data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "Model7 = GradientBoostingClassifier(learning_rate=0.1, n_estimators = 100)\n",
    "Model7.fit(X_train_valid2_s, y_train_valid2)\n",
    "np.mean(Model7.predict(X_test2_s) == y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:</b>\n",
    "- Since it is a binary classifiation (0/1), I use sigmoid function for my output layer and use binary_crossentropy as my loss to fit the model.\n",
    "- Looks like the accuracy of Neural Networks (98%) is much higher than the Logistic Regression model (53%). Gradient Boosting performs good as well, the accuracy is around 97%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
