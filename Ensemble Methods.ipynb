{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS 862 Machine Learning for Business Analysts Fall 2020\n",
    "\n",
    "### Ensemble Methods\n",
    "\n",
    "#### Submitted by:\n",
    "* Di Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Python demonstration I have showed you how to conduct ensemble modeling with regression. For this assignment, you will be doing ensemble with classification instead. Almost all the functions that we have covered have a classification version that you can directly apply (with a few changes ocassionally, of course).\n",
    "\n",
    "The dataset you will be using is a bank churn modeling found on [Kaggle](https://www.kaggle.com/shrutimechlearn/churn-modelling). The goal is to use the given information to predict whether a bank customer will churn or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings # Suppress warnings because they are annoying\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = pd.read_csv('bank_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First do some preprocessing. Remove the following columns: RowNumber, CustomerID, Surname. Convert categorical data into dummy variables (with dropping). Split data into 80%-20% train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the following columns\n",
    "data.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data into dummy variables \n",
    "data = pd.get_dummies(data, columns = ['Geography', 'Gender'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data \n",
    "X = data.copy()\n",
    "X = data.drop('Exited', axis = 1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now practice each of the ensemble methods we discussed. Your job is to build an ensemble classifier using each method, and provide me your evaluation (accuracy) on the test set. Remember to conduct the appropriate preprocessing (if needed). You may tune your models if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting (Soft) Classifier\n",
    "Use 5 classifiers, where two of them needs to be same but different hyperparameters. You can choose your own classifiers. Build a soft voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LR', LogisticRegression()), ('GB', GaussianNB()),\n",
       "                             ('DT', DecisionTreeClassifier(random_state=123)),\n",
       "                             ('RF1',\n",
       "                              RandomForestClassifier(n_estimators=50,\n",
       "                                                     random_state=123)),\n",
       "                             ('RF2',\n",
       "                              RandomForestClassifier(max_features=8,\n",
       "                                                     random_state=123))],\n",
       "                 n_jobs=2, voting='soft')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #Logistic \n",
    "from sklearn.naive_bayes import GaussianNB #Naive Bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier # This function is to perform voting classifier\n",
    "\n",
    "# Define the individual models\n",
    "LR = LogisticRegression()\n",
    "GB = GaussianNB()\n",
    "DT = DecisionTreeClassifier(random_state=123) \n",
    "RF1 = RandomForestClassifier(n_estimators=50, random_state=123)\n",
    "RF2 = RandomForestClassifier(max_features=8, random_state=123)\n",
    "\n",
    "# Fit the individual classifier\n",
    "LR.fit(X_train_s, y_train)\n",
    "GB.fit(X_train_s, y_train)\n",
    "DT.fit(X_train_s, y_train)\n",
    "RF1.fit(X_train_s, y_train)\n",
    "RF2.fit(X_train_s, y_train)\n",
    "\n",
    "# Fit the voting classifier\n",
    "vr = VotingClassifier(estimators = [('LR', LR), ('GB', GB), ('DT', DT), \n",
    "                                    ('RF1', RF1), ('RF2', RF2)], n_jobs = 2, voting='soft')\n",
    "vr.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting soft: 0.8575\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (accuracy) on the test set -- voting soft\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Voting soft:', accuracy_score(vr.predict(X_test_s), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting (Hard) Classifier\n",
    "Now do the same, but with a hard voting classifier. Compare the result with the soft classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LR', LogisticRegression()), ('GB', GaussianNB()),\n",
       "                             ('DT', DecisionTreeClassifier(random_state=123)),\n",
       "                             ('RF1',\n",
       "                              RandomForestClassifier(n_estimators=50,\n",
       "                                                     random_state=123)),\n",
       "                             ('RF2',\n",
       "                              RandomForestClassifier(max_features=8,\n",
       "                                                     random_state=123))],\n",
       "                 n_jobs=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the voting classifier\n",
    "vr2 = VotingClassifier(estimators = [('LR', LR), ('GB', GB), ('DT', DT), \n",
    "                                    ('RF1', RF1), ('RF2', RF2)], n_jobs = 2, voting='hard')\n",
    "vr2.fit(X_train_s, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting hard: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (accuracy) on the test set -- voting hard\n",
    "print('Voting hard:', accuracy_score(vr2.predict(X_test_s), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observation:** \n",
    "- For soft voting, every individual classifier provides a probability value, sum up the result with 20% for each model. \n",
    "- For hard voting, every individual classifier votes for a class. In this case, the final result will be the label predicted by 3 or more models.\n",
    "- The accuracy for soft voting is 85.75% and hard voting is 86%, quite similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a comparison, let's also fit the individual models and see if there's really an improvement with the voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.813\n",
      "Gaussian Naive Bayes: 0.8255\n",
      "Decision Tree: 0.8005\n",
      "RandomForest 1: 0.865\n",
      "RandomForest 2: 0.863\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (accuracy) on the test set -- individual models\n",
    "print('Logistic Regression:', accuracy_score(LR.predict(X_test_s), y_test))\n",
    "print('Gaussian Naive Bayes:', accuracy_score(GB.predict(X_test_s), y_test))\n",
    "print('Decision Tree:', accuracy_score(DT.predict(X_test_s), y_test))\n",
    "print('RandomForest 1:', accuracy_score(RF1.predict(X_test_s), y_test))\n",
    "print('RandomForest 2:', accuracy_score(RF2.predict(X_test_s), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observation:** \n",
    "- Looks like both voting models perform better than Logistic Regression, Gaussian Naive Bayes and decision tree. But two Random Forest models have a higher accuracy rate than the voting models. I think it make sense because the way RF doing is fitting a number of decision trees on various sub-samples of datasets and uses average to improve the predictive accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Logistic Regression\n",
    "Now fit a bagged model, using logistic regression as base. You can choose what logistic regression to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0 0 0 ... 0 0 0]\n",
      "Accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate the model\n",
    "bag_lr = BaggingClassifier(LogisticRegression(), n_estimators = 100)\n",
    "\n",
    "# Fit the model\n",
    "bag_lr.fit(X_train_s, y_train)\n",
    "\n",
    "# Prediction\n",
    "print('Prediction:', bag_lr.predict(X_test_s)) #2000 observations\n",
    "print('Accuracy:', bag_lr.score(X_test_s, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observation:** \n",
    "- The accuracy is 81.3%, which is same at the Logistic Regression Model we did in task 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "Now do the same, but with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.15687\n",
      "Will train until validation_0-error hasn't improved in 3 rounds.\n",
      "[1]\tvalidation_0-error:0.14625\n",
      "[2]\tvalidation_0-error:0.14938\n",
      "[3]\tvalidation_0-error:0.14750\n",
      "[4]\tvalidation_0-error:0.14375\n",
      "[5]\tvalidation_0-error:0.13937\n",
      "[6]\tvalidation_0-error:0.14000\n",
      "[7]\tvalidation_0-error:0.13937\n",
      "[8]\tvalidation_0-error:0.13625\n",
      "[9]\tvalidation_0-error:0.13625\n",
      "[10]\tvalidation_0-error:0.13562\n",
      "[11]\tvalidation_0-error:0.13562\n",
      "[12]\tvalidation_0-error:0.13500\n",
      "[13]\tvalidation_0-error:0.13562\n",
      "[14]\tvalidation_0-error:0.13437\n",
      "[15]\tvalidation_0-error:0.13312\n",
      "[16]\tvalidation_0-error:0.13312\n",
      "[17]\tvalidation_0-error:0.13250\n",
      "[18]\tvalidation_0-error:0.13375\n",
      "[19]\tvalidation_0-error:0.13750\n",
      "[20]\tvalidation_0-error:0.13312\n",
      "Stopping. Best iteration:\n",
      "[17]\tvalidation_0-error:0.13250\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.5, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 30}\n",
      "Accuracy: 0.861\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Get a validation set, 20% from training, don't change the testing set\n",
    "X1_train, X1_valid, y1_train, y1_valid = train_test_split(X_train, y_train, test_size = 0.2, \n",
    "                                                          random_state = 123)\n",
    "# Scale the data\n",
    "X1_train_s = scaler.fit_transform(X1_train)\n",
    "X1_valid_s = scaler.transform(X1_valid)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# tune parameter\n",
    "param = {'max_depth':range(3,8), 'min_child_weight':range(1,6),  \n",
    "        'n_estimators':[30,50], 'learning_rate':[0.1,0.5,1]}\n",
    "\n",
    "# Instantiate the model\n",
    "xgb_cla = GridSearchCV(XGBClassifier(random_state = 123), param, n_jobs = -2)\n",
    "\n",
    "# Fit the model\n",
    "xgb_cla.fit(X1_train_s, y1_train, eval_set = [(X1_valid_s, y1_valid)], \n",
    "            early_stopping_rounds = 3) \n",
    "print('Best Parameters:', xgb_cla.best_params_)\n",
    "\n",
    "# Prediction\n",
    "print('Accuracy:', accuracy_score(xgb_cla.predict(X_test_s), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observation:** \n",
    "- After tuning my model, looks like the best parameters are 0.5 learning rate, 3 max depth, 3 min child weight and 30 number of estimators. The accuracy on testing set is 86.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM\n",
    "Repeat with Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't set num_leaves and 2^max_depth > num_leaves\n",
      "[1]\tvalid_0's binary_logloss: 0.471383\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.449895\n",
      "[3]\tvalid_0's binary_logloss: 0.433233\n",
      "[4]\tvalid_0's binary_logloss: 0.420436\n",
      "[5]\tvalid_0's binary_logloss: 0.40954\n",
      "[6]\tvalid_0's binary_logloss: 0.400593\n",
      "[7]\tvalid_0's binary_logloss: 0.393311\n",
      "[8]\tvalid_0's binary_logloss: 0.38663\n",
      "[9]\tvalid_0's binary_logloss: 0.381325\n",
      "[10]\tvalid_0's binary_logloss: 0.376507\n",
      "[11]\tvalid_0's binary_logloss: 0.37183\n",
      "[12]\tvalid_0's binary_logloss: 0.367364\n",
      "[13]\tvalid_0's binary_logloss: 0.364379\n",
      "[14]\tvalid_0's binary_logloss: 0.360544\n",
      "[15]\tvalid_0's binary_logloss: 0.357906\n",
      "[16]\tvalid_0's binary_logloss: 0.356517\n",
      "[17]\tvalid_0's binary_logloss: 0.354766\n",
      "[18]\tvalid_0's binary_logloss: 0.352231\n",
      "[19]\tvalid_0's binary_logloss: 0.351109\n",
      "[20]\tvalid_0's binary_logloss: 0.35023\n",
      "[21]\tvalid_0's binary_logloss: 0.349013\n",
      "[22]\tvalid_0's binary_logloss: 0.347853\n",
      "[23]\tvalid_0's binary_logloss: 0.346957\n",
      "[24]\tvalid_0's binary_logloss: 0.346305\n",
      "[25]\tvalid_0's binary_logloss: 0.346131\n",
      "[26]\tvalid_0's binary_logloss: 0.345315\n",
      "[27]\tvalid_0's binary_logloss: 0.345321\n",
      "[28]\tvalid_0's binary_logloss: 0.344645\n",
      "[29]\tvalid_0's binary_logloss: 0.343814\n",
      "[30]\tvalid_0's binary_logloss: 0.34311\n",
      "[31]\tvalid_0's binary_logloss: 0.342966\n",
      "[32]\tvalid_0's binary_logloss: 0.342834\n",
      "[33]\tvalid_0's binary_logloss: 0.341806\n",
      "[34]\tvalid_0's binary_logloss: 0.342007\n",
      "[35]\tvalid_0's binary_logloss: 0.341659\n",
      "[36]\tvalid_0's binary_logloss: 0.341177\n",
      "[37]\tvalid_0's binary_logloss: 0.340683\n",
      "[38]\tvalid_0's binary_logloss: 0.340411\n",
      "[39]\tvalid_0's binary_logloss: 0.340065\n",
      "[40]\tvalid_0's binary_logloss: 0.34034\n",
      "[41]\tvalid_0's binary_logloss: 0.340115\n",
      "[42]\tvalid_0's binary_logloss: 0.340099\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's binary_logloss: 0.340065\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 50}\n",
      "Accuracy: 0.8635\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# tune parameter\n",
    "param = {'max_depth':range(3,8), 'min_child_weight':range(1,6), \n",
    "        'n_estimators':[30,50], 'learning_rate':[0.1,0.5,1]}\n",
    "\n",
    "# Instantiate the model\n",
    "lgbm_cla = GridSearchCV(LGBMClassifier(random_state = 123), param, n_jobs = -2)\n",
    "\n",
    "# Fit the model\n",
    "lgbm_cla.fit(X1_train_s, y1_train, eval_set = [(X1_valid_s, y1_valid)], \n",
    "            early_stopping_rounds = 3) \n",
    "print('Best Parameters:', lgbm_cla.best_params_)\n",
    "\n",
    "# Prediction\n",
    "print('Accuracy:', accuracy_score(lgbm_cla.predict(X_test_s), y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observation:** \n",
    "- After tuning my model, looks like the best parameters are 0.1 learning rate, 6 max depth, 3 min child weight and 50 number of estimators. The accuracy on testing set is 86.35%.\n",
    "- Looks like Light BGM performs a little better than XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "Lastly, do this with Stacking. You may use the same models you used from the voting classifiers. Choose your own blender function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the base learners -- same models from task 1 voting\n",
    "LR = LogisticRegression()\n",
    "GB = GaussianNB()\n",
    "DT = DecisionTreeClassifier(random_state=123) \n",
    "RF1 = RandomForestClassifier(n_estimators=50, random_state=123)\n",
    "RF2 = RandomForestClassifier(max_features=8, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will define the base learners. We will put them in a dictionary\n",
    "models = {'LR': LR, 'GB': GB, 'DT': DT, 'RF1': RF1, 'RF2': RF2}\n",
    "\n",
    "# Also define the blender\n",
    "from sklearn.svm import SVC \n",
    "blender = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into 2vparts, 1 to train the weak learners, another to train the blender\n",
    "X_train_1, X_train_2, y_train1, y_train2 = train_test_split(X_train, y_train, \n",
    "                                                              test_size = 0.5, random_state = 123)\n",
    "\n",
    "# Scale the data\n",
    "X_train_s1 = scaler.fit_transform(X_train_1)\n",
    "X_train_s2 = scaler.transform(X_train_2)\n",
    "X_test_s1 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the weak learners\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_s1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the blender\n",
    "# Get the prediction\n",
    "predictions = pd.DataFrame() # Set up a dataframe to store the predictions\n",
    "for name, model in models.items():\n",
    "    predictions[name] = model.predict_proba(X_train_s2)[:,1]\n",
    "\n",
    "# Get the blender\n",
    "scaler_blend = StandardScaler() # Scale the predictions for SVR\n",
    "predictions_scale = scaler_blend.fit_transform(predictions)\n",
    "blender.fit(predictions_scale, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>GB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF1</th>\n",
       "      <th>RF2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037972</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.259700</td>\n",
       "      <td>0.234523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.307226</td>\n",
       "      <td>0.326384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.262999</td>\n",
       "      <td>0.253475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035705</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.544092</td>\n",
       "      <td>0.647458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.125885</td>\n",
       "      <td>0.275384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0.087630</td>\n",
       "      <td>0.099164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.124042</td>\n",
       "      <td>0.142009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.042837</td>\n",
       "      <td>0.039567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LR        GB   DT   RF1   RF2\n",
       "0     0.037972  0.021811  0.0  0.00  0.00\n",
       "1     0.259700  0.234523  0.0  0.26  0.20\n",
       "2     0.307226  0.326384  0.0  0.04  0.00\n",
       "3     0.262999  0.253475  1.0  0.74  0.70\n",
       "4     0.035705  0.020135  0.0  0.00  0.00\n",
       "...        ...       ...  ...   ...   ...\n",
       "3995  0.544092  0.647458  1.0  0.46  0.43\n",
       "3996  0.125885  0.275384  1.0  0.82  0.90\n",
       "3997  0.087630  0.099164  0.0  0.06  0.10\n",
       "3998  0.124042  0.142009  1.0  0.28  0.14\n",
       "3999  0.042837  0.039567  0.0  0.06  0.08\n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8575"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform evaluation\n",
    "# First send the data through the weak learners\n",
    "predictions = pd.DataFrame() # Set up a dataframe to store the predictions\n",
    "for name, model in models.items():\n",
    "    predictions[name] = model.predict_proba(X_test_s1)[:,1]\n",
    "    \n",
    "# Prediction through the blender, and evaluate\n",
    "predictions_scale = scaler_blend.transform(predictions)\n",
    "accuracy_score(blender.predict(predictions_scale), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Observation:** \n",
    "\n",
    "| Dataset | Voting soft | Voting hard | Bagged Logistic Regression | XGBoost | Light GBM | Stacking \n",
    "| --- | --- | --- | --- | --- | --- | --- | \n",
    "| Churn Modelling | .8575 | .8600 | .8130 | .8610 | .8635 | .8575 | \n",
    "\n",
    "- Looks like the results of different Ensemble Methods are quite similar, the best one is 86.35% from Light GBM, and the worst one is 81.30% from Bagged Logistic Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
