{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am importing only pandas and numpy. Import the rest of libraries (only the necessary ones)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#for split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "#for decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeRegressor   #Decision Tree Regressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import recall_score\n",
    "# Set up pipeline \n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some online resources  http://ocw.uc3m.es/ingenieria-informatica/machine-learning-i/decisiontreeshyperparameters.html/skinless_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupation</th>\n",
       "      <th>region</th>\n",
       "      <th>nkids</th>\n",
       "      <th>nkids2</th>\n",
       "      <th>nadults</th>\n",
       "      <th>lnx</th>\n",
       "      <th>stobacco</th>\n",
       "      <th>salcohol</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bluecol</td>\n",
       "      <td>flanders</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.19054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inactself</td>\n",
       "      <td>flanders</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.90857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>whitecol</td>\n",
       "      <td>flanders</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.97461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bluecol</td>\n",
       "      <td>flanders</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.76281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inactself</td>\n",
       "      <td>flanders</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.80800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  occupation    region  nkids  nkids2  nadults       lnx  stobacco  salcohol  \\\n",
       "0    bluecol  flanders      1       0        2  14.19054       0.0  0.000000   \n",
       "1  inactself  flanders      0       0        3  13.90857       0.0  0.002285   \n",
       "2   whitecol  flanders      0       0        1  13.97461       0.0  0.012875   \n",
       "3    bluecol  flanders      1       0        2  13.76281       0.0  0.005907   \n",
       "4  inactself  flanders      2       0        1  13.80800       0.0  0.021981   \n",
       "\n",
       "   age  \n",
       "0    2  \n",
       "1    3  \n",
       "2    2  \n",
       "3    2  \n",
       "4    2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TobaccoData = pd.read_csv(\"Tobacco.csv\")\n",
    "del TobaccoData['Unnamed: 0']\n",
    "TobaccoData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, you will use different variables to predict the expenditure on tobacco. Here is the data dictionary of this dataset:\n",
    "https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Tobacco.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nkids</th>\n",
       "      <th>nkids2</th>\n",
       "      <th>nadults</th>\n",
       "      <th>lnx</th>\n",
       "      <th>stobacco</th>\n",
       "      <th>salcohol</th>\n",
       "      <th>occupation_inactself</th>\n",
       "      <th>occupation_whitecol</th>\n",
       "      <th>region_flanders</th>\n",
       "      <th>region_walloon</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.19054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.90857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.97461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.76281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.80800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021981</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nkids  nkids2  nadults       lnx  stobacco  salcohol  occupation_inactself  \\\n",
       "0      1       0        2  14.19054       0.0  0.000000                     0   \n",
       "1      0       0        3  13.90857       0.0  0.002285                     1   \n",
       "2      0       0        1  13.97461       0.0  0.012875                     0   \n",
       "3      1       0        2  13.76281       0.0  0.005907                     0   \n",
       "4      2       0        1  13.80800       0.0  0.021981                     1   \n",
       "\n",
       "   occupation_whitecol  region_flanders  region_walloon  age_1  age_2  age_3  \\\n",
       "0                    0                1               0      0      1      0   \n",
       "1                    0                1               0      0      0      1   \n",
       "2                    1                1               0      0      1      0   \n",
       "3                    0                1               0      0      1      0   \n",
       "4                    0                1               0      0      1      0   \n",
       "\n",
       "   age_4  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables for the categorical variables, and remove the unncessary columns\n",
    "# Note: age here is a categorical variable. It represents age group\n",
    "# You should have a total of 17 columns afterwards (including the response)\n",
    "\n",
    "occupation = pd.get_dummies(TobaccoData.occupation, prefix = 'occupation', drop_first = True)\n",
    "region = pd.get_dummies(TobaccoData.region, prefix = 'region', drop_first = True)\n",
    "age = pd.get_dummies(TobaccoData.age, prefix = 'age', drop_first = True)\n",
    "TobaccoData = pd.concat([TobaccoData, occupation, region, age], axis = 1)\n",
    "del TobaccoData['occupation']\n",
    "del TobaccoData['region']\n",
    "del TobaccoData['age']\n",
    "TobaccoData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2724, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TobaccoData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We would like to use a Regression Tree model to detect the most important variables affect expenditure on tobacco. Follow necessary steps to develop your Regression Tree, tune it via _Cross-Validation_ and lastly state the most important variable you found with the corresponding MSE of your best model. Your output is stobacco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the X and Y\n",
    "\n",
    "X = TobaccoData.copy() \n",
    "del X['stobacco']\n",
    "y = TobaccoData['stobacco']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a 5-fold cross validation to tune the max_depth and max_leaf_nodes arguments simultaneously. Set the random state in the decision tree to be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training and holdout set. Use the random state 1, and 30% hold-out size.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=1, splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 50),\n",
       "                         'max_leaf_nodes': range(2, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune your tree \n",
    "decision_tree =  DecisionTreeRegressor(random_state=1) # There is no preprocessing, so we just have one input\n",
    "\n",
    "paras = {'max_depth': range(2,50), \n",
    "        'max_leaf_nodes': range(2,50)} # Discrete uniform distribution between 2 and 50\n",
    "clf = GridSearchCV(decision_tree, paras, n_jobs = -1, cv = 5) \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'max_leaf_nodes': 4}\n",
      "0.0005496823796275048\n",
      "0.023445306132091875\n"
     ]
    }
   ],
   "source": [
    "# Report the best parameters and MSE on the test set\n",
    "print(clf.best_params_)\n",
    "# This is how we perform prediction\n",
    "print(mean_squared_error(clf.predict(X_test), y_test))\n",
    "print(np.sqrt(mean_squared_error(clf.predict(X_test), y_test))) # Calculate RMSE instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now repeat the procedure, but this time tune the alpha parameter. Feel free to refine your choice to get a better estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=1, splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'ccp_alpha': array([0.00000000e+00, 1.11111111e-06, 2.22222222e-06, 3.33333333e-06,\n",
       "       4.44444444e-06, 5.55555556e-06, 6.66666667e-06, 7.77777778e-06,\n",
       "       8.88888889e-06, 1.00000000e-05])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune your tree. Use values between 0 to 1e-5.\n",
    "decision_tree = DecisionTreeRegressor(random_state=1) # There is no preprocessing, so we just have one input\n",
    "\n",
    "paras = {'ccp_alpha': np.linspace(0, 0.00001, 10)}\n",
    "clf1 = GridSearchCV(decision_tree, paras, n_jobs = -1, cv = 5) \n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 1e-05}\n",
      "0.0005515078450825027\n",
      "0.02348420416114846\n"
     ]
    }
   ],
   "source": [
    "# Report the best parameters and MSE on the test set\n",
    "print(clf1.best_params_)\n",
    "# This is how we perform prediction\n",
    "print(mean_squared_error(clf1.predict(X_test), y_test))\n",
    "print(np.sqrt(mean_squared_error(clf1.predict(X_test), y_test))) # Calculate RMSE instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe?\n",
    "Answer: The performances are similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now refit the two models (using the training set) with the best parameters respectively, and report the important features from both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=1e-05, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the two models\n",
    "grid = DecisionTreeRegressor(max_depth = clf.best_params_['max_depth'],\n",
    "                      max_leaf_nodes = clf.best_params_['max_leaf_nodes'])\n",
    "grid1 = DecisionTreeRegressor(ccp_alpha = clf1.best_params_['ccp_alpha'])\n",
    "grid.fit(X_train, y_train)\n",
    "grid1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Model1</th>\n",
       "      <th>Model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lnx</td>\n",
       "      <td>0.62096</td>\n",
       "      <td>0.580324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>age_4</td>\n",
       "      <td>0.37904</td>\n",
       "      <td>0.419676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nkids</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nkids2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nadults</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>salcohol</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>occupation_inactself</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>occupation_whitecol</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>region_flanders</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>region_walloon</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>age_1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>age_2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>age_3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature   Model1    Model2\n",
       "3                    lnx  0.62096  0.580324\n",
       "12                 age_4  0.37904  0.419676\n",
       "0                  nkids  0.00000  0.000000\n",
       "1                 nkids2  0.00000  0.000000\n",
       "2                nadults  0.00000  0.000000\n",
       "4               salcohol  0.00000  0.000000\n",
       "5   occupation_inactself  0.00000  0.000000\n",
       "6    occupation_whitecol  0.00000  0.000000\n",
       "7        region_flanders  0.00000  0.000000\n",
       "8         region_walloon  0.00000  0.000000\n",
       "9                  age_1  0.00000  0.000000\n",
       "10                 age_2  0.00000  0.000000\n",
       "11                 age_3  0.00000  0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report the important features from both models\n",
    "importance = pd.DataFrame({'feature':X_train.columns.values, \n",
    "                           'Model1':grid.feature_importances_,\n",
    "                          'Model2': grid1.feature_importances_})\n",
    "importance.sort_values(by = 'Model1', ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's your observation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Both models agree with the top 2 most important features (in the same order). The regularized tree only has two selected predictor, which (might) indicate it's a very small tree, we need to investigate more on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also plot your second tree. It should be small enough to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 181.2, 'lnx <= 13.334\\nmse = 0.001\\nsamples = 1906\\nvalue = 0.013'),\n",
       " Text(83.7, 108.72, 'age_4 <= 0.5\\nmse = 0.001\\nsamples = 410\\nvalue = 0.023'),\n",
       " Text(41.85, 36.23999999999998, 'mse = 0.002\\nsamples = 224\\nvalue = 0.031'),\n",
       " Text(125.55000000000001, 36.23999999999998, 'mse = 0.001\\nsamples = 186\\nvalue = 0.012'),\n",
       " Text(251.10000000000002, 108.72, 'lnx <= 14.04\\nmse = 0.0\\nsamples = 1496\\nvalue = 0.01'),\n",
       " Text(209.25, 36.23999999999998, 'mse = 0.001\\nsamples = 979\\nvalue = 0.012'),\n",
       " Text(292.95, 36.23999999999998, 'mse = 0.0\\nsamples = 517\\nvalue = 0.006')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw your tree here\n",
    "small_clf = DecisionTreeRegressor(max_depth = 2)\n",
    "small_clf.fit(X_train, y_train)\n",
    "tree.plot_tree(small_clf, feature_names=X_train.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's treat stobacco as a dummy variable to distinguish between those who smoke and who do not. We then use decision tree classifier to identify the most important features that may affect probability of smoking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nkids</th>\n",
       "      <th>nkids2</th>\n",
       "      <th>nadults</th>\n",
       "      <th>lnx</th>\n",
       "      <th>salcohol</th>\n",
       "      <th>occupation_inactself</th>\n",
       "      <th>occupation_whitecol</th>\n",
       "      <th>region_flanders</th>\n",
       "      <th>region_walloon</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>smoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.19054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.90857</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.97461</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.76281</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.80800</td>\n",
       "      <td>0.021981</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.00313</td>\n",
       "      <td>0.016691</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.88680</td>\n",
       "      <td>0.069258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.00711</td>\n",
       "      <td>0.026909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.33985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.99883</td>\n",
       "      <td>0.031385</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nkids  nkids2  nadults       lnx  salcohol  occupation_inactself  \\\n",
       "0      1       0        2  14.19054  0.000000                     0   \n",
       "1      0       0        3  13.90857  0.002285                     1   \n",
       "2      0       0        1  13.97461  0.012875                     0   \n",
       "3      1       0        2  13.76281  0.005907                     0   \n",
       "4      2       0        1  13.80800  0.021981                     1   \n",
       "5      3       0        2  14.00313  0.016691                     0   \n",
       "6      0       0        2  13.88680  0.069258                     1   \n",
       "7      1       0        2  14.00711  0.026909                     0   \n",
       "8      0       0        2  14.33985  0.000000                     0   \n",
       "9      0       0        2  13.99883  0.031385                     1   \n",
       "\n",
       "   occupation_whitecol  region_flanders  region_walloon  age_1  age_2  age_3  \\\n",
       "0                    0                1               0      0      1      0   \n",
       "1                    0                1               0      0      0      1   \n",
       "2                    1                1               0      0      1      0   \n",
       "3                    0                1               0      0      1      0   \n",
       "4                    0                1               0      0      1      0   \n",
       "5                    1                1               0      0      1      0   \n",
       "6                    0                1               0      0      0      0   \n",
       "7                    0                1               0      0      0      0   \n",
       "8                    1                1               0      1      0      0   \n",
       "9                    0                1               0      0      0      0   \n",
       "\n",
       "   age_4  smoke  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "5      0      0  \n",
       "6      1      1  \n",
       "7      0      0  \n",
       "8      0      0  \n",
       "9      1      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dummy variable called smoke, that takes the value 0 if stobacco is 0, and 1 otherwise. \n",
    "# Delete your stobacco column afterwards\n",
    "# The smoke variable is now your response\n",
    "\n",
    "TobaccoData['smoke'] = (TobaccoData['stobacco'] > 0).astype(int)\n",
    "del TobaccoData['stobacco']\n",
    "TobaccoData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-extract predictors and responses\n",
    "\n",
    "X1 = TobaccoData.copy() \n",
    "del X1['smoke']\n",
    "y1 = TobaccoData['smoke']\n",
    "\n",
    "# Split data\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the classification trees, follow the same tunings above. Report the important variables for the two models. Use recall as your evaluation metric. You will need to do some customerization on the scoring part. See https://stackoverflow.com/questions/50933561/how-to-specify-positive-label-when-use-precision-as-scoring-in-gridsearchcv for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=1, splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(2, 50),\n",
       "                         'max_leaf_nodes': range(2, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune your tree with max_depth and max_leaf_nodes\n",
    "decision_tree = DecisionTreeClassifier(random_state=1) \n",
    "\n",
    "paras = {'max_depth': range(2,50), # Discrete uniform distribution between 2 and 50\n",
    "        'max_leaf_nodes': range(2,50),\n",
    "        'criterion': ['gini', 'entropy']} \n",
    "clf2 = GridSearchCV(decision_tree, paras, n_jobs = -1, cv = 5) \n",
    "clf2.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 4, 'max_leaf_nodes': 8}\n",
      "0.0891089108910891\n"
     ]
    }
   ],
   "source": [
    "# Report the best parameters and the recall value on the test set\n",
    "# Recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "\n",
    "print(clf2.best_params_)\n",
    "# This is how we perform prediction\n",
    "print(recall_score(y1_test, clf2.predict(X1_test)))\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=1, splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'ccp_alpha': array([0.00000000e+00, 1.11111111e-06, 2.22222222e-06, 3.33333333e-06,\n",
       "       4.44444444e-06, 5.55555556e-06, 6.66666667e-06, 7.77777778e-06,\n",
       "       8.88888889e-06, 1.00000000e-05]),\n",
       "                         'criterion': ['gini', 'entropy']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune your tree with ccp_alpha \n",
    "decision_tree = DecisionTreeClassifier(random_state=1) # There is no preprocessing, so we just have one input\n",
    "\n",
    "paras = {'ccp_alpha': np.linspace(0, 0.00001, 10),\n",
    "        'criterion': ['gini', 'entropy']}\n",
    "clf3 = GridSearchCV(decision_tree, paras, n_jobs = -1, cv = 5) \n",
    "clf3.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'criterion': 'entropy'}\n",
      "0.44884488448844884\n"
     ]
    }
   ],
   "source": [
    "# Report the best parameters and the recall value on the test set\n",
    "\n",
    "print(clf3.best_params_)\n",
    "# This is how we perform prediction\n",
    "print(recall_score(y1_test, clf3.predict(X1_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's your observation? \n",
    "\n",
    "Answer: From the recall value, it is clearly that the first decisiton tree model with 'max_depth'=4 and 'max_leaf_nodes'=8 is not perform well. Even the second model 'ccp_alpha'=0 only has 46.9% of recall value. The result means that among all the actual positive outputs, we only prodict correctly with less than half of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now refit the two models with the best parameters, and get the important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the two models\n",
    "grid2 = DecisionTreeClassifier(max_depth = clf2.best_params_['max_depth'],\n",
    "                      max_leaf_nodes = clf2.best_params_['max_leaf_nodes'],\n",
    "                             criterion = clf2.best_params_['criterion'])\n",
    "grid3 = DecisionTreeClassifier(ccp_alpha = clf3.best_params_['ccp_alpha'],\n",
    "                              criterion = clf3.best_params_['criterion'])\n",
    "grid2.fit(X1_train, y1_train)\n",
    "grid3.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Model3</th>\n",
       "      <th>Model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>age_4</td>\n",
       "      <td>0.403999</td>\n",
       "      <td>0.017530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lnx</td>\n",
       "      <td>0.256018</td>\n",
       "      <td>0.422727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>salcohol</td>\n",
       "      <td>0.194153</td>\n",
       "      <td>0.327448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nadults</td>\n",
       "      <td>0.145830</td>\n",
       "      <td>0.033886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nkids</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nkids2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>occupation_inactself</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>occupation_whitecol</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>region_flanders</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>region_walloon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>age_1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>age_2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>age_3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature    Model3    Model4\n",
       "12                 age_4  0.403999  0.017530\n",
       "3                    lnx  0.256018  0.422727\n",
       "4               salcohol  0.194153  0.327448\n",
       "2                nadults  0.145830  0.033886\n",
       "0                  nkids  0.000000  0.058920\n",
       "1                 nkids2  0.000000  0.005958\n",
       "5   occupation_inactself  0.000000  0.019148\n",
       "6    occupation_whitecol  0.000000  0.012439\n",
       "7        region_flanders  0.000000  0.023206\n",
       "8         region_walloon  0.000000  0.026398\n",
       "9                  age_1  0.000000  0.011924\n",
       "10                 age_2  0.000000  0.026784\n",
       "11                 age_3  0.000000  0.013631"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important features\n",
    "importance = pd.DataFrame({'feature':X1_train.columns.values, \n",
    "                           'Model3':grid2.feature_importances_,\n",
    "                          'Model4': grid3.feature_importances_})\n",
    "importance.sort_values(by = 'Model3', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's your observation?\n",
    "\n",
    "Answer: It shows Model 3 is quite simple, with only 4 important features. However, Model 4 shows a different result, even the important features are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
